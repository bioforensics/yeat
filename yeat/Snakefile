# -------------------------------------------------------------------------------------------------
# Copyright (c) 2021, DHS. This file is part of YEAT: http://github.com/bioforensics/yeat
#
# This software was prepared for the Department of Homeland Security (DHS) by the Battelle National
# Biodefense Institute, LLC (BNBI) as part of contract HSHQDC-15-C-00064 to manage and operate the
# National Biodefense Analysis and Countermeasures Center (NBACC), a Federally Funded Research and
# Development Center.
# -------------------------------------------------------------------------------------------------

from shutil import copyfile
import pandas as pd


rule all:
    input:
        expand("analysis/quast/{assembler}/{sample}_report.html", assembler=config["assemblers"], sample=config["sample"]),
        expand("seq/fastqc/{sample}_{reads}_fastqc.html", sample=config["sample"], reads=["R1", "R2"])


rule copyinput:
    output:
        read1="seq/input/{sample}_R1.fq.gz",
        read2="seq/input/{sample}_R2.fq.gz"
    input:
        read1=config["read1"],
        read2=config["read2"]
    run:
        copyfile(input.read1, output.read1)
        copyfile(input.read2, output.read2)


rule fastqc:
    output:
        out1="seq/fastqc/{sample}_R1_fastqc.html",
        out2="seq/fastqc/{sample}_R2_fastqc.html"
    input:
        read1="seq/input/{sample}_R1.fq.gz",
        read2="seq/input/{sample}_R2.fq.gz"
    threads: 128
    shell:
        """
        fastqc {input.read1} {input.read2} --threads {threads} -o seq/fastqc/
        """


rule fastp:
    output:
        out1="seq/fastp/{sample}.R1.fq.gz",
        out2="seq/fastp/{sample}.R2.fq.gz"
    input:
        read1="seq/input/{sample}_R1.fq.gz",
        read2="seq/input/{sample}_R2.fq.gz"
    shell:
        """
        fastp -i {input.read1} -I {input.read2} -o {output.out1} -O {output.out2} \
            --html seq/fastp/fastp.html --json seq/fastp/fastp.json \
            2> seq/fastp/report.txt
        """


rule mash:
    output:
        sketch="seq/mash/{sample}.R1.fq.gz.msh",
        mash_report="seq/mash/{sample}.report.tsv"
    input:
        read1="seq/fastp/{sample}.R1.fq.gz"
    shell:
        """
        mash sketch {input.read1} -o {output.sketch}
        mash info -t {output.sketch} > {output.mash_report}
        """


rule downsample:
    output:
        sub1="seq/downsample/{sample}.R1.fq.gz",
        sub2="seq/downsample/{sample}.R2.fq.gz"
    input:
        read1="seq/fastp/{sample}.R1.fq.gz",
        read2="seq/fastp/{sample}.R2.fq.gz",
        mash_report="seq/mash/{sample}.report.tsv"
    run:
        result = input.mash_report
        df = pd.read_csv(result, sep="\t")
        genome_size = df["Length"].iloc[0]
        coverage = 150
        read_length = 250
        down = (genome_size * 150) // (2 * read_length)
        print(f"genome size: {genome_size}")
        print(f"down: {down}")
        shell("seqtk sample {input.read1} {down} > seq/downsample/{wildcards.sample}.R1.fq")
        shell("seqtk sample {input.read2} {down} > seq/downsample/{wildcards.sample}.R2.fq")
        shell("gzip -f seq/downsample/*")


rule spades:
    output:
        contigs="analysis/spades/{sample}_contigs.fasta"
    input:
        read1="seq/downsample/{sample}.R1.fq.gz",
        read2="seq/downsample/{sample}.R2.fq.gz"
    threads: 128
    shell:
        """
        spades.py -1 {input.read1} -2 {input.read2} -t {threads} -o analysis/spades {config[extraargs][spades]}
        ln -s scaffolds.fasta {output.contigs}
        """


rule megahit:
    output:
        contigs="analysis/megahit/{sample}_contigs.fasta"
    input:
        read1="seq/downsample/{sample}.R1.fq.gz",
        read2="seq/downsample/{sample}.R2.fq.gz"
    threads: 128
    shell:
        """
        megahit -1 {input.read1} -2 {input.read2} -t {threads} -o analysis/megahit-temp {config[extraargs][megahit]}
        mv analysis/megahit-temp/* analysis/megahit
        rm -r analysis/megahit-temp
        ln -s final.contigs.fa {output.contigs}
        """


rule unicycler:
    output:
        contigs="analysis/unicycler/{sample}_contigs.fasta"
    input:
        read1="seq/downsample/{sample}.R1.fq.gz",
        read2="seq/downsample/{sample}.R2.fq.gz"
    shell:
        """
        unicycler -1 {input.read1} -2 {input.read2} -t {threads} -o analysis/unicycler {config[extraargs][unicycler]}
        ln -s assembly.fasta {output.contigs}
        """


rule quast:
    output:
        report="analysis/quast/{assembler}/{sample}_report.html"
    input:
        contigs="analysis/{assembler}/{sample}_contigs.fasta"
    shell:
        """
        quast.py {input.contigs} -o analysis/quast/{wildcards.assembler}
        ln -s report.html {output.report}
        """
